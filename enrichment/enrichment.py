## enrichment.py 0.2

# Jamie Shallcross
# Whelan Lab
# Department of Chemistry & Biochemistry
# Oberlin College
# LAST MODIFIED 5/24/14
#
# Tentative GPL License (feel free to use, modify, distribute, but give credit and keep it open source)
#
# Hosted at https://github.com/rebeccawhelan/PythonEnrichment
# Send bug reports to jshallcr@cs.oberlin.edu or rwhelan@oberlin.edu
# Further development or bug fixes are welcomed.
#
#    This program was created to analyze high throughput sequencing data produced from 
#    SELEX type experiments. The idea is that the overall percent enrichment between the 
#    unselected library and the final round of selection, the so-called "fold enrichment" is more 
#    indicative of a successful aptamer sequence than just overall abundance in later rounds. 
#    Given that libraries are often not truly random, and PCR may favor some sequences over others,
#    an initial bias can give a certain sequence a head start over other sequences that are better 
#    able to bind the target. Enrichment analysis helps overcome these biases.  
#
#    Intended to be invoked as follows:
#
#        python enrichment.py [flags] [base_file] [secondary_file_a] [secondary_file_b] ...
#
#
#    All files should be in the form of sequence-count files (comma delimited csv by default), 
#    such as those generated by the Jellyfish program or Biopieces using the "write_tab" function. 
#    A command such as:
#
#          awk '!(NR%2){print$0","p}{p=$0}' | sed 's/>//g' > [outfile]
#
#    can be used to transform fasta files that use the sequence count as a header
#    into the correct input format. All fields after the first two are ignored, but sequence
#    and count must be the first two fields. To strip out other fields, use cut. 
#
#
#   Output is as CSV, sorted by the highest degrees of enrichment from first to final rounds,
#   and should be openable in spreadsheet programs like OpenOffice or Excel, as well as opened
#   by UNIX tools. 
# 
#   Requires that NumPy be installed. NumPy can be downloaded at http://www.scipy.org/install.html


import numpy as np
import csv, sys, argparse

def main():

    #Global user-input values and flags
    global SUB_0                #Weight given to "zero-count" sequences 
        #Fraction that zero abundance counts in earlier rounds are treated
        #Nessesary to count enrichment from those sequences in the library zero times
        #Change to place more/less weight on unsequenced reads. Make 0 to ignore them. 
    global THRESH               #Minimum count from basefile to include
    global DELIM                #Delimiter for input archive files 
    global N_RECORDS            #Number of sequences to output as CSV lines
    global V                    #Verbose Flag

    ## READ ARGS ##

    ap = argparse.ArgumentParser(description="Calculate enrichment over rounds of SELEX")   #Create an argparser object
    

    # Add arguments

    ap.add_argument("base_file", type=argparse.FileType('r'),  
            help="Sequence-count file to which all others are compared, usually the final round or round with highest bulk affinity")

    ap.add_argument("-o", "--outfile", nargs='?', type=argparse.FileType('w'), default=sys.stdout, 
            help="File to which output will be written as CSV. Writes to stdout by default.")

    ap.add_argument("-d", "--delimiter", default=',', 
            help="Delimiter for input files between a sequence and it's count. Defaults to ',' use '\\t' for tab.")
    
    ap.add_argument("-w", "--zero_weight",  type=float, default=0.5,
            help="Weight given to sequences counted zero times, but which appear in later rounds. The default is 0.5, but this has relatively little theoretical basis.")

    ap.add_argument("-t", "--threshhold",   type=int, default=0, 
            help="Minimum count for a sequence to be included in the analysis. Default is 0.")

    ap.add_argument("-n", "--records", type=int, default=sys.maxint,  
            help="Number of sorted enrichment records to emit. Default is all.") 

    ap.add_argument("-v", "--verbose", action="store_true", 
            help="Print verbose output, including progress reports and the mean and median of the data loaded.")

    ap.add_argument("secondary_files", nargs="+", type=argparse.FileType('r'), 
            help="List of sequence-count files, usually earlier SELEX rounds you want to compare to the basefile")
    

    #Parse args, assign to requisite variables
    args = ap.parse_args()

    base_file       = args.base_file
    secondary_files = args.secondary_files
    outfile         = args.outfile
    SUB_0           = args.zero_weight
    THRESH          = args.threshhold
    DELIM           = args.delimiter
    if DELIM == r"\t":
        DELIM = "\t"
    N_RECORDS       = args.records
    V               = args.verbose


    rounds = len(secondary_files) + 1 
    count_array, index, height = create_table(base_file, rounds) #Create an index and numpy array from round of interest

    if V: 
        print "Array created, %d entries" % (height)

    for i, round_file in enumerate(secondary_files): #Should be passing by ref, so count_array gets modified and doesn't need to be returned
        fill_table(round_file, i, count_array, index)

    if V: 
        print "Array Filled"

    #Build a header to go with output
    header = ["##", "Sequence", "Length"] + [file.name for file in secondary_files] + [base_file.name] 
    for round in secondary_files:
        header.append("%s to %s" % (round.name, base_file.name))

    
    #Numerical calculations 
    do_math(count_array, rounds, header)


    if V:
        print "Math Done"

    reverse_index = {v:k for k, v in index.iteritems()} #Swap key:value pairs
    if V:
        print "Index Reversed"


    sorted_output(count_array, reverse_index, rounds, header, outfile)


    if V:
        print "Done"
    exit()

def create_table(file, rounds):


    num_seq = sum(1 for line in file) #Max number of sequences possible (if THRESH = 0 then this many are read)
    file.seek(0) #Reset file pointer

    #Allocate an initial array of N floats, where N is the most possible sequences (as determined above)
    #Floats are used to allow "zero abundance" counts to be treated as fractional
    tmp_array = np.zeros(num_seq, dtype=np.float64)

    index = {} #Empty dict to map sequence -> np array index

    if V:
        print "Loading all above %d" % (THRESH)

    i = 0
    for line in file:
        # ** Add a try-catch block to catch bad delimters **
        try:
            seq, count = line.split(DELIM, 2)[:2]
        except ValueError:
            print "Unable to parse file using current delimiter '%s'. Exiting." % (DELIM)
            exit()
        try:
            #Only add values above the threshhold 
            if int(count) > THRESH:              
                tmp_array[i] = int(count) 
                index[seq] = i
                i += 1  #aka i++
        except ValueError:
            continue        #This skips all lines that don't have a number in the second column, such as header lines. 
    
    count_array = np.empty((i, 2*rounds - 1), dtype=np.float64)  
    count_array.fill(SUB_0) #Fill with dummy value
    count_array[:, rounds-1] = tmp_array[0:i]

    return count_array, index, i


def fill_table(file, round, count_array, index):

    if V:
        print "Filling round %d" % (round)

    #This is the most labor intensive loop, 
    for line in file:
        seq, count = line.split(DELIM, 2)[:2]
        try:
            if seq in index:
                pos = index[seq]
                count_array[pos, round] = count
        except ValueError:
            continue



def do_math(count_array, n_rounds, header):


    #Calculate enrichments
    for i in xrange(n_rounds - 1):
        #Divide the final abundance by the current column, store it in the next unoccupied column
        count_array[:, n_rounds + i] = count_array[:, n_rounds - 1] / count_array[:, i] 

    if V:
        print header[2:] #Lables for stats
        #Find the average of all the columns, put it in the bottom column (shortcut -1)
        average =  np.mean(count_array[0:-1], axis=0, dtype=np.float64) 
        median = np.median(count_array[0:-1], axis=0) 

        print "Median :" + str(median)
        print "Mean :" + str(average)




def sorted_output(count_array, reverse_index, rounds, header, file):

    if V:
        print "Sorting"

    sort = np.argsort(count_array[:, rounds])   #Produce list of indices, sorted by the first secondary file (from least to greatest)
    sort = sort[::-1]                           #Reverse List, so greatest is first
    sort = sort[:N_RECORDS]                     #Cut to the number of records to be emitted

    wr = csv.writer(file, dialect='excel')  #Create CSV writer object
    wr.writerow(header)

    for j, i in enumerate(sort):
        wr.writerow( [j+1] + [reverse_index[i]] + [len(reverse_index[i])] + list(count_array[i,:].astype(np.int32)) )   #Cast as int so that zero counts are listed that way, rounds down
        #Also assuming that the output should be indexed by one. Change "j+1" to just "j" to index by zero.
        # j+1 is a counter, reverse_index[i] is the sequence, and list(count_array... is the full list of counts and enrichments
    
    if V:
        print "Output written"

if __name__ == "__main__":
    main()
